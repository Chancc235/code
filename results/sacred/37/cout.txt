[INFO 06:27:43] pymarl Running command 'my_main'
[INFO 06:27:43] pymarl Started run with ID "37"
[DEBUG 06:27:43] pymarl Starting Heartbeat
[DEBUG 06:27:43] my_main Started
[WARNING 06:27:43] my_main episodes_per_teammate was changed to 0
[INFO 06:27:43] my_main Experiment Parameters:
[INFO 06:27:43] my_main 

{   'agent': 'rnn',
    'batch_size': 512,
    'batch_size_run': 1024,
    'buffer_cpu_only': True,
    'buffer_size': 32,
    'checkpoint_path': '',
    'critic_lr': 0.0005,
    'cur_episodes': 32,
    'env': 'stag_hunt',
    'env_args': {   'agent_move_block': [   0,
                                            1,
                                            2],
                    'agent_obs': [   2,
                                     2],
                    'capture_action': False,
                    'capture_action_conditions': [   2,
                                                     1],
                    'capture_conditions': [   0,
                                              1],
                    'capture_freezes': False,
                    'capture_terminal': False,
                    'directed_cone_narrow': True,
                    'directed_exta_actions': True,
                    'directed_observations': False,
                    'episode_limit': 200,
                    'intersection_global_view': False,
                    'intersection_unknown': False,
                    'is_print': False,
                    'miscapture_punishment': 0,
                    'mountain_agent_row': -1,
                    'mountain_slope': 0.0,
                    'mountain_spawn': False,
                    'n_agents': 2,
                    'n_hare': 0,
                    'n_stags': 4,
                    'need_render': False,
                    'observe_ids': False,
                    'observe_one_hot': False,
                    'observe_state': False,
                    'observe_walls': False,
                    'p_hare_rest': 0.0,
                    'p_stags_rest': 0.0,
                    'prevent_cannibalism': True,
                    'print_caught_prey': False,
                    'print_frozen_agents': False,
                    'random_ghosts': False,
                    'random_ghosts_indicator': False,
                    'random_ghosts_mul': -1,
                    'random_ghosts_prob': 0.5,
                    'remove_frozen': True,
                    'reward_collision': 0,
                    'reward_hare': 1,
                    'reward_stag': 10,
                    'reward_time': 0,
                    'state_as_graph': False,
                    'toroidal': False,
                    'world_shape': [   10,
                                       10]},
    'episodes_per_teammate': 0,
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'exp_name': 'stage1_PP',
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'ind': 'stage1',
    'inner_loop_episodes': 128,
    'label': 'default_label',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'local_saves_path': 'saves',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'basic',
    'meta_update_times': 8,
    'n_sub_modules': 4,
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'optimize_meta': True,
    'points_per_teammate': 64,
    'pop': 'stage1',
    'population_alg': 'vdn',
    'population_size': 4,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'runner': 'meta',
    'runner_log_interval': 10000,
    'save_BR': False,
    'save_BR_episodes': 2048,
    'save_model': False,
    'save_model_interval': 2000000,
    'save_population': True,
    'save_population_episodes': 2048,
    'save_replay': False,
    'seed': 912088939,
    't_max': 5000000,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 1024,
    'test_percent': 0.2,
    'train_test_split': False,
    'use_cuda': True,
    'use_history': False,
    'use_tensorboard': True,
    'z_dim': 8}

[INFO 06:28:10] my_main ================ MetaEpoch: 0 ================
[INFO 06:28:10] my_main Time passed: 0 seconds
[INFO 06:28:10] root [Individual 0] Begin training for 128 episodes
[INFO 06:35:14] root t_env: 204800 / 5000000
[INFO 06:35:14] root Estimated time left: 2 hours, 37 minutes, 42 seconds. Time passed: 7 minutes, 3 seconds
[INFO 06:35:55] root [Individual 1] Begin training for 128 episodes
[INFO 06:43:04] root t_env: 204800 / 5000000
[INFO 06:43:04] root Estimated time left: 2 hours, 39 minutes, 36 seconds. Time passed: 7 minutes, 8 seconds
[INFO 06:43:46] root [Individual 2] Begin training for 128 episodes
[INFO 06:50:52] root t_env: 204800 / 5000000
[INFO 06:50:52] root Estimated time left: 2 hours, 38 minutes, 33 seconds. Time passed: 7 minutes, 6 seconds
[INFO 06:51:36] root [Individual 3] Begin training for 128 episodes
[INFO 06:58:51] root t_env: 204800 / 5000000
[INFO 06:58:51] root Estimated time left: 2 hours, 41 minutes, 46 seconds. Time passed: 7 minutes, 14 seconds
[INFO 06:59:32] my_main [Population] Meta Train for 8 updates
[INFO 06:59:58] root Saving models to results/stage1_PP__2024-10-21_06-27-43_kENntZ/models/0/204800
[INFO 06:59:58] root Saving models to results/stage1_PP__2024-10-21_06-27-43_kENntZ/models/1/204800
[INFO 06:59:58] root Saving models to results/stage1_PP__2024-10-21_06-27-43_kENntZ/models/2/204800
[INFO 06:59:58] root Saving models to results/stage1_PP__2024-10-21_06-27-43_kENntZ/models/3/204800
[INFO 06:59:58] my_main ================ MetaEpoch: 1 ================
[INFO 06:59:58] my_main Time passed: 31 minutes, 47 seconds
[INFO 06:59:58] root [Individual 0] Begin training for 128 episodes
[INFO 07:00:39] root Updated target network
[INFO 07:06:46] root t_env: 409600 / 5000000
[INFO 07:06:46] root Estimated time left: 11 hours, 46 minutes, 51 seconds. Time passed: 38 minutes, 36 seconds
[INFO 07:07:23] root [Individual 1] Begin training for 128 episodes
[INFO 07:08:06] root Updated target network
