{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/home/cike/code/src",
    "dependencies": [
      "munch==2.5.0",
      "numpy==1.21.6",
      "PyYAML==6.0.1",
      "sacred==0.8.2",
      "torch==1.13.1"
    ],
    "mainfile": "meta_main.py",
    "name": "pymarl",
    "repositories": [],
    "sources": [
      [
        "meta_main.py",
        "_sources/meta_main_a74be827ec41963b97b9ab4d77c6d25a.py"
      ],
      [
        "utils/config_utils.py",
        "_sources/config_utils_11a418cc99d65a52a4ab3d9c9e93f913.py"
      ],
      [
        "utils/logging.py",
        "_sources/logging_867f86b10403f8b7e6826558d04fb18e.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/home/cike/anaconda3/envs/pymarl/lib/python3.7/site-packages/sacred/config/captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"src/meta_main.py\", line 43, in my_main\n    run(_run, config, _log)\n",
    "  File \"src/meta_main.py\", line 80, in run\n    pop.run()\n",
    "  File \"/home/cike/code/src/meta/population/stage1_population.py\", line 159, in run\n    self.train_inner_all()\n",
    "  File \"/home/cike/code/src/meta/population/stage1_population.py\", line 83, in train_inner_all\n    self.train_inner(ind_id)\n",
    "  File \"/home/cike/code/src/meta/population/stage1_population.py\", line 77, in train_inner\n    self.dones[ind_id] = self.individuals[ind_id].train()\n",
    "  File \"/home/cike/code/src/meta/individual/stage1_individual.py\", line 95, in train\n    log_train_status=(i == n_runs-1))\n",
    "  File \"/home/cike/code/src/runners/meta_runner.py\", line 207, in run\n    self.reset()\n",
    "  File \"/home/cike/code/src/runners/meta_runner.py\", line 142, in reset\n    self.batch = self.new_batch()\n",
    "  File \"/home/cike/code/src/components/episode_buffer.py\", line 30, in __init__\n    self._setup_data(self.scheme, self.groups, batch_size, max_seq_length, self.preprocess)\n",
    "  File \"/home/cike/code/src/components/episode_buffer.py\", line 78, in _setup_data\n    (batch_size, max_seq_length, *shape), dtype=dtype, device=self.device)\n",
    "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 47.46 GiB total capacity; 1.68 MiB already allocated; 20.31 MiB free; 2.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
  ],
  "heartbeat": "2024-10-18T08:06:11.245489",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz",
    "gpus": {
      "driver_version": "470.182.03",
      "gpus": [
        {
          "model": "Quadro RTX 8000",
          "persistence_mode": false,
          "total_memory": 48601
        },
        {
          "model": "Tesla P100-PCIE-16GB",
          "persistence_mode": false,
          "total_memory": 16280
        },
        {
          "model": "Tesla P100-PCIE-16GB",
          "persistence_mode": false,
          "total_memory": 16280
        },
        {
          "model": "Quadro RTX 8000",
          "persistence_mode": false,
          "total_memory": 48601
        },
        {
          "model": "Tesla P100-PCIE-16GB",
          "persistence_mode": false,
          "total_memory": 16280
        },
        {
          "model": "Tesla P100-PCIE-16GB",
          "persistence_mode": false,
          "total_memory": 16280
        }
      ]
    },
    "hostname": "89ddac7113b8",
    "os": [
      "Linux",
      "Linux-4.15.0-213-generic-x86_64-with-debian-buster-sid"
    ],
    "python_version": "3.7.12"
  },
  "meta": {
    "command": "my_main",
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [],
      "help": false,
      "with": false
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2024-10-18T08:06:05.822546",
  "status": "FAILED",
  "stop_time": "2024-10-18T08:06:11.248813"
}